{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCICIO 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries.\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cmath\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to training the classificator\n",
    "x_train = np.array(['Chinese Beijing Chinese','Chinese Chinese Shanghai','Chinese Macao','Tokyo Japan Chinese'])\n",
    "\n",
    "# Labels to training the classificator\n",
    "y_train = np.array(['china','china','china','not china'])\n",
    "\n",
    "# Test of the classificator\n",
    "X_test = np.array(['Chinese Chinese Chinese Tokyo Japan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador naive Bayes com distribuição de Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts.\n",
    "vect = CountVectorizer(binary=True)\n",
    "\n",
    "# Fit and transform X_train into x_train_dtm (document-term matrices - dtm).\n",
    "X_train_dtm = vect.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome dos atributos Bernoulli\n",
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "Matriz com a contagem dos atributos\n",
      "[[1 1 0 0 0 0]\n",
      " [0 1 0 0 1 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Counting Matrix\n",
    "print('Nome dos atributos Bernoulli')\n",
    "print(vect.get_feature_names())\n",
    "print('Matriz com a contagem dos atributos')\n",
    "print(X_train_dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidde Beijing|China 0.16666666666666666\n",
      "Probabilidde Chinese|China 0.3333333333333333\n",
      "Probabilidde Japan|China 0.08333333333333333\n",
      "Probabilidde Macao|China 0.16666666666666666\n",
      "Probabilidde Shanghai|China 0.16666666666666666\n",
      "Probabilidde Tokyo|China 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Probabilidade \n",
    "P_China = 3/4\n",
    "P_not_China = 1/4\n",
    "\n",
    "# China\n",
    "'P(Contagem(Beijing | China) = 1'\n",
    "'P(Contagem(Chinese | China) = 3'\n",
    "'P(Contagem(Japan | China) = 0' \n",
    "'P(Contagem(Macao | China) = 1'\n",
    "'P(Contagem(Shanghai | China) = 1'\n",
    "'P(Contagem(Tokyo | China) = 0'\n",
    "'sum_(k=1)**(K) contagem(Xk,china) = 6'\n",
    "\n",
    "#P(Beijing | China)\n",
    "P_Beijing_china = (1 + 1)/(6+6)\n",
    "print('Probabilidde Beijing|China', P_Beijing_china)\n",
    "\n",
    "#P(Chinese | China)\n",
    "P_Chinese_china = (3 + 1)/(6+6)\n",
    "print('Probabilidde Chinese|China', P_Chinese_china)\n",
    "\n",
    "#P(Japan | China)\n",
    "P_japan_china = (0+1)/(6+6)\n",
    "print('Probabilidde Japan|China', P_japan_china)\n",
    "\n",
    "#P(Macao | China)\n",
    "P_Macao_china = (1 + 1)/(6 + 6)\n",
    "print('Probabilidde Macao|China', P_Macao_china)\n",
    "\n",
    "#P(Shanghai | China)\n",
    "P_Shangai_china = (1 + 1)/(6 + 6)\n",
    "print('Probabilidde Shanghai|China',P_Shangai_china)\n",
    "\n",
    "#P(Tokyo | China)\n",
    "P_Tokyo_china = (0 + 1)/(6+6)\n",
    "print('Probabilidde Tokyo|China', P_Tokyo_china)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidde Beijing Not China 0.1111111111111111\n",
      "Probabilidde Chinese Not China 0.2222222222222222\n",
      "Probabilidde Japan Not China 0.2222222222222222\n",
      "Probabilidde Macao Not China 0.1111111111111111\n",
      "Probabilidde Shangai Not China 0.1111111111111111\n",
      "Probabilidde Tokyo Not China 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Not China\n",
    "'P(Contagem(Beijing | Not China) = 0'\n",
    "'P(Contagem(Chinese | Not China) = 1'\n",
    "'P(Contagem(Japan | Not China) = 1'\n",
    "'P(Contagem(Macao | Not China) = 0'\n",
    "'P(Contagem(Shanghai | Not China) = 0'\n",
    "'P(Contagem(Tokyo | Not China) = 1'\n",
    "'sum_(k=1)**(K) contagem(Xk, Not China) = 3'\n",
    "\n",
    "#P(Beijing | Not China)\n",
    "P_Beijing_not_china =(0 + 1)/(3 + 6)\n",
    "print('Probabilidde Beijing Not China', P_Beijing_not_china)\n",
    "\n",
    "#P(Chinese | Not China)\n",
    "P_chinese_not_china = (1 + 1)/(3 + 6)\n",
    "print('Probabilidde Chinese Not China', P_chinese_not_china)\n",
    "\n",
    "#P(Japan | Not China)\n",
    "P_Japan_not_China = (1 + 1)/(3 + 6)\n",
    "print ('Probabilidde Japan Not China', P_Japan_not_China)\n",
    "\n",
    "#P(Macao | Not China)\n",
    "P_Macao_not_China = (0 + 1)/(3 + 6)\n",
    "print('Probabilidde Macao Not China', P_Macao_not_China)\n",
    "\n",
    "#P(Shanghai | Not China)\n",
    "P_Shangai_not_China = (0 + 1)/(3 + 6)\n",
    "print('Probabilidde Shangai Not China', P_Shangai_not_China)\n",
    "\n",
    "#P(Tokyo | Not China)\n",
    "P_Tokyo_not_China = (1 + 1)/(3 + 6)\n",
    "print('Probabilidde Tokyo Not China', P_Tokyo_not_China)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade 0.011111111111111112\n",
      "Probabilidade 0.0027434842249657062\n"
     ]
    }
   ],
   "source": [
    "# Prevendo\n",
    "\n",
    "#P(China |Chinese, Chinese, Chinese, Tokyo, Japan) \n",
    "\n",
    "P_Ch_Chi_Chi_Tokyo_Japan = P_China * P_Chinese_china * P_Tokyo_china * P_japan_china\n",
    "print('Probabilidade', P_Ch_Chi_Chi_Tokyo_Japan)\n",
    "\n",
    "#P(Not China |Chinese, Chinese, Chinese, Tokyo, Japan)\n",
    "P_not_Ch_chi_Chi_Tokyo_Japan = P_not_China * P_chinese_not_china * P_Tokyo_not_China * P_Japan_not_China\n",
    "print('Probabilidade', P_not_Ch_chi_Chi_Tokyo_Japan )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Existe maior probabilidade de ser Not China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Bernoulli Naive Bayes model.\n",
    "nb = BernoulliNB(binarize=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=None, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the MultinomialNB model.\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "[[0 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Transform document into document-term matrix.\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "# Perform classification on an array of test vectors X_test_dtm.\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "print(vect.get_feature_names())\n",
    "print(X_test_dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not china']\n",
      "[[0.19106679 0.80893321]]\n"
     ]
    }
   ],
   "source": [
    "# Getting the probabilities for each class.\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "print(y_pred_class)\n",
    "print(nb.predict_proba(X_test_dtm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resposta :\n",
    "\n",
    "O vetor de teste para indicador positivo para a feature 'chinese' ocorre três vezes, sendo assim o peso é maior do que as ocorrências negativas das features 'japan' e 'to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to training the classificator\n",
    "x_train = np.array(['Chinese Beijing Chinese','Chinese Chinese Shanghai','Chinese Macao','Tokyo Japan Chinese'])\n",
    "\n",
    "# Labels to training the classificator\n",
    "y_train = np.array(['china','china','china','not china'])\n",
    "\n",
    "# Test of the classificator\n",
    "X_test = np.array(['Chinese Chinese Chinese Tokyo Japan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts.\n",
    "vect_multi = CountVectorizer(binary=False)\n",
    "\n",
    "# Fit and transform X_train into x_train_dtm (document-term matrices - dtm).\n",
    "X_train_dtm_multi = vect_multi.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nome dos atributos Bernoulli\n",
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "Matriz com a contagem dos atributos\n",
      "[[1 2 0 0 0 0]\n",
      " [0 2 0 0 1 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Counting Matrix\n",
    "print('Nome dos atributos Bernoulli')\n",
    "print(vect.get_feature_names())\n",
    "print('Matriz com a contagem dos atributos')\n",
    "print(X_train_dtm_multi.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidde Beijing|China 0.14285714285714285\n",
      "Probabilidde Chinese|China 0.42857142857142855\n",
      "Probabilidde Japan|China 0.07142857142857142\n",
      "Probabilidde Macao|China 0.14285714285714285\n",
      "Probabilidde Shanghai|China 0.14285714285714285\n",
      "Probabilidde Tokyo|China 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "#Probabilidade \n",
    "P_China = 3/4\n",
    "P_not_China = 1/4\n",
    "\n",
    "# China\n",
    "'P(Contagem(Beijing | China) = 1'\n",
    "'P(Contagem(Chinese | China) = 5'\n",
    "'P(Contagem(Japan | China) = 0' \n",
    "'P(Contagem(Macao | China) = 1'\n",
    "'P(Contagem(Shanghai | China) = 1'\n",
    "'P(Contagem(Tokyo | China) = 0'\n",
    "'sum_(k=1)**(K) contagem(Xk,china) = 8'\n",
    "\n",
    "#P(Beijing | China)\n",
    "P_Beijing_china_ = (1 + 1)/(8+6)\n",
    "print('Probabilidde Beijing|China', P_Beijing_china_)\n",
    "\n",
    "#P(Chinese | China)\n",
    "P_Chinese_china_ = (5 + 1)/(8+6)\n",
    "print('Probabilidde Chinese|China', P_Chinese_china_)\n",
    "\n",
    "#P(Japan | China)\n",
    "P_japan_china_ = (0+1)/(8+6)\n",
    "print('Probabilidde Japan|China', P_japan_china_)\n",
    "\n",
    "#P(Macao | China)\n",
    "P_Macao_china_ = (1 + 1)/(8 + 6)\n",
    "print('Probabilidde Macao|China', P_Macao_china_)\n",
    "\n",
    "#P(Shanghai | China)\n",
    "P_Shangai_china_ = (1 + 1)/(8+6)\n",
    "print('Probabilidde Shanghai|China',P_Shangai_china_)\n",
    "\n",
    "#P(Tokyo | China)\n",
    "P_Tokyo_china_ = (0 + 1)/(8+6)\n",
    "print('Probabilidde Tokyo|China', P_Tokyo_china_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidde Beijing Not China 0.1111111111111111\n",
      "Probabilidde Chinese Not China 0.2222222222222222\n",
      "Probabilidde Japan Not China 0.2222222222222222\n",
      "Probabilidde Macao Not China 0.1111111111111111\n",
      "Probabilidde Shangai Not China 0.1111111111111111\n",
      "Probabilidde Tokyo Not China 0.2222222222222222\n"
     ]
    }
   ],
   "source": [
    "# Not China\n",
    "'P(Contagem(Beijing | Not China) = 0'\n",
    "'P(Contagem(Chinese | Not China) = 1'\n",
    "'P(Contagem(Japan | Not China) = 1'\n",
    "'P(Contagem(Macao | Not China) = 0'\n",
    "'P(Contagem(Shanghai | Not China) = 0'\n",
    "'P(Contagem(Tokyo | Not China) = 1'\n",
    "'sum_(k=1)**(K) contagem(Xk, Not China) = 3'\n",
    "\n",
    "#P(Beijing | Not China)\n",
    "P_Beijing_not_china_ =(0 + 1)/(3 + 6)\n",
    "print('Probabilidde Beijing Not China', P_Beijing_not_china_)\n",
    "\n",
    "#P(Chinese | Not China)\n",
    "P_chinese_not_china_ = (1 + 1)/(3 + 6)\n",
    "print('Probabilidde Chinese Not China', P_chinese_not_china_)\n",
    "\n",
    "#P(Japan | Not China)\n",
    "P_Japan_not_China_ = (1 + 1)/(3 + 6)\n",
    "print ('Probabilidde Japan Not China', P_Japan_not_China_)\n",
    "\n",
    "#P(Macao | Not China)\n",
    "P_Macao_not_China_ = (0 + 1)/(3 + 6)\n",
    "print('Probabilidde Macao Not China', P_Macao_not_China_)\n",
    "\n",
    "#P(Shanghai | Not China)\n",
    "P_Shangai_not_China_ = (0 + 1)/(3 + 6)\n",
    "print('Probabilidde Shangai Not China', P_Shangai_not_China_)\n",
    "\n",
    "#P(Tokyo | Not China)\n",
    "P_Tokyo_not_China_ = (1 + 1)/(3 + 6)\n",
    "print('Probabilidde Tokyo Not China', P_Tokyo_not_China_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade 0.00030121377997263036\n",
      "Probabilidade 0.008230452674897118\n"
     ]
    }
   ],
   "source": [
    "# Prevendo\n",
    "\n",
    "#P(China |Chinese, Chinese, Chinese, Tokyo, Japan) \n",
    "P_Ch_Chi_Chi_Tokyo_Japan_ = P_China * ((P_Chinese_china_)**3) * P_Tokyo_china_ * P_japan_china_\n",
    "print('Probabilidade', P_Ch_Chi_Chi_Tokyo_Japan_)\n",
    "\n",
    "#P(Not China |Chinese, Chinese, Chinese, Tokyo, Japan)\n",
    "P_not_Ch_chi_Chi_Tokyo_Japan_ = P_not_China * ((P_chinese_not_china_)*3) * P_Tokyo_not_China_ * P_Japan_not_China_\n",
    "print('Probabilidade', P_not_Ch_chi_Chi_Tokyo_Japan_ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Existe maior probabilidade de ser China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Bernoulli Naive Bayes model.\n",
    "nb_multi = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm\n",
    "nb_multi.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beijing', 'chinese', 'japan', 'macao', 'shanghai', 'tokyo']\n",
      "[[0 1 1 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# Transform document into document-term matrix.\n",
    "X_test_dtm_multi = vect_multi.transform(X_test)\n",
    "\n",
    "# Perform classification on an array of test vectors X_test_dtm.\n",
    "y_pred_class_multi = nb_multi.predict(X_test_dtm_multi)\n",
    "print(vect.get_feature_names())\n",
    "print(X_test_dtm.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidade Multinomial\n",
      "['china']\n",
      "[[0.58742949 0.41257051]]\n"
     ]
    }
   ],
   "source": [
    "# Getting the probabilities for each class.\n",
    "y_pred_class_multi = nb_multi.predict(X_test_dtm_multi)\n",
    "print('Probabilidade Multinomial')\n",
    "print(y_pred_class_multi)\n",
    "print(nb_multi.predict_proba(X_test_dtm_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resposta:\n",
    "\n",
    "O motivo dessa classificação é que as três ocorrências do indicador positivo 'chinese' no vetor de test superam (tem maior peso) do que as ocorrências dos dois indicadores negativos 'japan' e 'tokyo'. No Classificador Bernoulli os atributos são Booleanos independentes,  e ele não conta os elementos repetidos\n",
    "diferente do Multinomial os atributos são discretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
